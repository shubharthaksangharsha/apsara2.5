/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
*/
import {GoogleGenAI} from '@google/genai';
import {ChatState, marked, Playground} from './playground';

const SYSTEM_INSTRUCTIONS = `you're an extremely proficient creative coding agent, and can code effects, games, generative art.
write javascript code assuming it's in a live p5js environment.
return the code block.
you can include a short paragraph explaining your reasoning and the result in human readable form.
there can be no external dependencies: all functions must be in the returned code.
make extra sure that all functions are either declared in the code or part of p5js.
the user can modify the code, go along with the user's changes.`;

const EMPTY_CODE = `function setup() {
  // Setup code goes here.
  createCanvas(windowWidth, windowHeight);
}

function draw() {
  // Frame drawing code goes here.
  background(175);
}`;

/* make a simple animation of the background color */
const STARTUP_CODE = `function setup() {
  createCanvas(windowWidth, windowHeight);
  // Set color mode to HSB (Hue, Saturation, Brightness)
  // Hue ranges from 0 to 360, Saturation and Brightness from 0 to 100
  colorMode(HSB, 360, 100, 100);
}

function draw() {
  // Calculate a hue value that changes over time
  // Use frameCount, which increments each frame
  // Multiply by a small number to slow down the color change
  // Use the modulo operator (%) to wrap the hue value around 360
  let hue = (frameCount * 0.5) % 360;

  // Set the background color using the calculated hue
  // Keep saturation and brightness high for vivid colors
  background(hue, 90, 90);
}

// Optional: Resize the canvas if the browser window size changes
function windowResized() {
  resizeCanvas(windowWidth, windowHeight);
}`;

const EXAMPLE_PROMPTS = [
  'make an arcade game',
  'make a bouncing yellow ball within a square, make sure to handle collision detection properly. make the square slowly rotate. make sure ball stays within the square',
  'make a smoke simulation made of puffy trails of smoke over a green landscape',
  'create a game where a space ship shoots asteroids flying around me in space',
];

const ai = new GoogleGenAI({
  apiKey: globalThis.process.env.API_KEY,
  apiVersion: 'v1alpha',
});

function createAiChat() {
  return ai.chats.create({
    model: 'gemini-2.5-pro-preview-03-25',
    config: {
      systemInstruction: SYSTEM_INSTRUCTIONS,
      thinkingConfig: {
        includeThoughts: true,
      },
    },
  });
}

let aiChat = createAiChat();

function getCode(text: string) {
  const startMark = '```javascript';
  const codeStart = text.indexOf(startMark);
  let codeEnd = text.lastIndexOf('```');

  if (codeStart > -1) {
    if (codeEnd < 0) {
      codeEnd = undefined;
    }
    return text.substring(codeStart + startMark.length, codeEnd);
  }
  return '';
}

document.addEventListener('DOMContentLoaded', async (event) => {
  const rootElement = document.querySelector('#root')! as HTMLElement;

  const playground = new Playground();
  rootElement.appendChild(playground);

  playground.sendMessageHandler = async (
    input: string,
    role: string,
    code: string,
    codeHasChanged: boolean,
  ) => {
    console.log(
      'sendMessageHandler',
      input,
      role,
      code,
      'codeHasChanged:',
      codeHasChanged,
    );

    const {thinking, text} = playground.addMessage('assistant', '');
    const message = [];

    if (role.toUpperCase() === 'USER' && codeHasChanged) {
      message.push({
        role: 'user',
        text: 'I have updated the code: ```javascript\n' + code + '\n```',
      });
    }

    if (role.toUpperCase() === 'SYSTEM') {
      message.push({
        role: 'user',
        text: `Interpreter reported: ${input}. Is it possible to improve that?`,
      });
    } else {
      message.push({
        role,
        text: input,
      });
    }

    playground.setChatState(ChatState.GENERATING);

    text.innerHTML = '...';

    let newCode = '';
    let thought = '';

    try {
      const res = await aiChat.sendMessageStream({message});

      for await (const chunk of res) {
        for (const candidate of chunk.candidates ?? []) {
          for (const part of candidate.content.parts ?? []) {
            if (part.thought) {
              playground.setChatState(ChatState.THINKING);
              thought += part.text;
              thinking.innerHTML = await marked.parse(thought);
              thinking.parentElement.classList.remove('hidden');
            } else if (part.text) {
              playground.setChatState(ChatState.CODING);
              newCode += part.text;
              const p5Code = getCode(newCode);

              // Remove the code block, it is available in the Code tab
              const explanation = newCode.replace(
                '```javascript' + p5Code + '```',
                '',
              );

              text.innerHTML = await marked.parse(explanation);
            }
            playground.scrollToTheEnd();
          }
        }
      }
    } catch (e: GoogleGenAI.ClientError) {
      console.error('GenAI SDK Error:', e.message);
      let message = e.message;
      const splitPos = e.message.indexOf('{');
      if (splitPos > -1) {
        const msgJson = e.message.substring(splitPos);
        try {
          const sdkError = JSON.parse(msgJson);
          if (sdkError.error) {
            message = sdkError.error.message;
            message = await marked.parse(message);
          }
        } catch (e) {
          console.error('Unable to parse the error message:', e);
        }
      }
      const {text} = playground.addMessage('error', '');
      text.innerHTML = message;
    }

    // close thinking block
    thinking.parentElement.removeAttribute('open');

    // If the answer was just code
    if (text.innerHTML.trim().length === 0) {
      text.innerHTML = 'Done';
    }

    const p5Code = getCode(newCode);
    if (p5Code.trim().length > 0) {
      playground.setCode(p5Code);
    } else {
      playground.addMessage('SYSTEM', 'There is no new code update.');
    }
    playground.setChatState(ChatState.IDLE);
  };

  playground.resetHandler = async () => {
    aiChat = createAiChat();
  };

  playground.setDefaultCode(EMPTY_CODE);
  playground.addMessage(
    'USER',
    'make a simple animation of the background color',
  );
  playground.addMessage('ASSISTANT', 'Here you go!');
  playground.setCode(STARTUP_CODE);
  playground.setInputField(
    'Start from scratch and ' +
      EXAMPLE_PROMPTS[Math.floor(Math.random() * EXAMPLE_PROMPTS.length)],
  );
});


DOCS: 

Gemini thinking
The Gemini 2.5 series models use an internal "thinking process" that significantly improves their reasoning and multi-step planning abilities, making them highly effective for complex tasks such as coding, advanced mathematics, and data analysis.

This guide shows you how to work with Gemini's thinking capabilities using the Gemini API.

Before you begin
Ensure you use a supported 2.5 series model for thinking. You might find it beneficial to explore these models in AI Studio before diving into the API:

Try Gemini 2.5 Flash Preview in AI Studio
Try Gemini 2.5 Pro Preview in AI Studio
Note: Thinking is enabled by default for the 2.5 series models. Read the section on setting a thinking budget for details and configuration.
Generating content with thinking
Initiating a request with a thinking model is similar to any other content generation request. The key difference lies in specifying one of the models with thinking support in the model field, as demonstrated in the following text generation example:

Python
JavaScript
Go
REST

import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: "GOOGLE_API_KEY" });

async function main() {
  const prompt = "Explain the concept of Occam's Razor and provide a simple, everyday example.";

  const response = await ai.models.generateContent({
    model: "gemini-2.5-flash-preview-05-20",  
    contents: prompt,
  });

  console.log(response.text);
}

main();
Thought summaries (Experimental)
Thought summaries offer insights into the model's internal reasoning process. This feature can be valuable for verifying the model's approach and keeping users informed during longer tasks, especially when combined with streaming.

You can enable thought summaries by setting includeThoughts to true in your request configuration. You can then access the summary by iterating through the response parameter's parts, and checking the thought boolean.

Here's an example demonstrating how to enable and retrieve thought summaries without streaming, which returns a single, final thought summary with the response:

Python
JavaScript
Go

import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: "GOOGLE_API_KEY" });

async function main() {
  const response = await ai.models.generateContent({
    model: "gemini-2.5-flash-preview-05-20",
    contents: "What is the sum of the first 50 prime numbers?",
    config: {
      thinkingConfig: {
        includeThoughts: true,
      },
    },
  });

  for (const part of response.candidates[0].content.parts) {
    if (!part.text) {
      continue;
    }
    else if (part.thought) {
      console.log("Thoughts summary:");
      console.log(part.text);
    }
    else {
      console.log("Answer:");
      console.log(part.text);
    }
  }
}

main();

And here is an example using thinking with streaming, which returns rolling, incremental summaries during generation:

Python
JavaScript

import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: "GOOGLE_API_KEY" });

const prompt = `Alice, Bob, and Carol each live in a different house on the same
street: red, green, and blue. The person who lives in the red house owns a cat.
Bob does not live in the green house. Carol owns a dog. The green house is to
the left of the red house. Alice does not own a cat. Who lives in each house,
and what pet do they own?`;

let thoughts = "";
let answer = "";

async function main() {
  const response = await ai.models.generateContentStream({
    model: "gemini-2.5-flash-preview-05-20",
    contents: prompt,
    config: {
      thinkingConfig: {
        includeThoughts: true,
      },
    },
  });

  for await (const chunk of response) {
    for (const part of chunk.candidates[0].content.parts) {
      if (!part.text) {
        continue;
      } else if (part.thought) {
        if (!thoughts) {
          console.log("Thoughts summary:");
        }
        console.log(part.text);
        thoughts = thoughts + part.text;
      } else {
        if (!answer) {
          console.log("Answer:");
        }
        console.log(part.text);
        answer = answer + part.text;
      }
    }
  }
}

await main();
Thinking budgets
The thinkingBudget parameter lets you guide the model on the number of thinking tokens it can use when generating a response. A higher token count generally allows for more detailed reasoning, which can be beneficial for tackling more complex tasks. If you don't set the thinkingBudget, the model will dynamically adjust the budget based on the complexity of the request.

The thinkingBudget must be an integer in the range 0 to 24576.
Setting the thinking budget to 0 disables thinking.
Depending on the prompt, the model might overflow or underflow the token budget.
Note: thinkingBudget is only supported in Gemini 2.5 Flash.
Python
JavaScript
Go
REST

import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: "GOOGLE_API_KEY" });

async function main() {
  const response = await ai.models.generateContent({
    model: "gemini-2.5-flash-preview-05-20",
    contents: "Provide a list of 3 famous physicists and their key contributions",
    config: {
      thinkingConfig: {
        thinkingBudget: 1024,
      },
    },
  });

  console.log(response.text);
}

main();
Pricing
Note: Summaries are available in the free and paid tiers of the API.
When thinking is turned on, response pricing is the sum of output tokens and thinking tokens. You can get the total number of generated thinking tokens from the thoughtsTokenCount field.

Python
JavaScript
Go

// ...
console.log(`Thoughts tokens: ${response.usageMetadata.thoughtsTokenCount}`);
console.log(`Output tokens: ${response.usageMetadata.candidatesTokenCount}`);
Thinking models generate full thoughts to improve the quality of the final response, and then output summaries to provide insight into the thought process. So, pricing is based on the full thought tokens the model needs to generate to create a summary, despite only the summary being output from the API.

You can learn more about tokens in the Token counting guide.

Supported Models
You can find all model capabilities on the model overview page.

Model	Thinking summaries	Thinking budget
Gemini 2.5 Flash	✔️	✔️
Gemini 2.5 Pro	✔️	X
Best practices
This section includes some guidance for using thinking models efficiently. As always, following our prompting guidance and best practices will get you the best results.

Debugging and steering
Review reasoning: When you're not getting your expected response from the thinking models, it can help to carefully analyze Gemini's reasoning process. You can see how it broke down the task and arrived at its conclusion, and use that information to correct towards the right results.

Provide Guidance in Reasoning: If you're hoping for a particularly lengthy output, you may want to provide guidance in your prompt to constrain the amount of thinking the model uses. This lets you reserve more of the token output for your response.

Task complexity
Easy Tasks (Thinking could be OFF): For straightforward requests where complex reasoning isn't required, such as fact retrieval or classification, thinking is not required. Examples include:
"Where was DeepMind founded?"
"Is this email asking for a meeting or just providing information?"
Medium Tasks (Default/Some Thinking): Many common requests benefit from a degree of step-by-step processing or deeper understanding. Gemini can flexibly use thinking capability for tasks like:
Analogize photosynthesis and growing up.
Compare and contrast electric cars and hybrid cars.
Hard Tasks (Maximum Thinking Capability): For truly complex challenges, the model needs to engage its full reasoning and planning capabilities, often involving many internal steps before providing an answer. Examples include:
Solve problem 1 in AIME 2025: Find the sum of all integer bases b > 9 for which 17b is a divisor of 97b.
Write Python code for a web application that visualizes real-time stock market data, including user authentication. Make it as efficient as possible.
Thinking with tools and capabilities
Thinking models work with all of Gemini's tools and capabilities. This allows the models to interact with external systems, execute code, or access real-time information, incorporating the results into their reasoning and final response.

The search tool allows the model to query Google Search to find up-to-date information or information beyond its training data. This is useful for questions about recent events or highly specific topics.

The code execution tool enables the model to generate and run Python code to perform calculations, manipulate data, or solve problems that are best handled algorithmically. The model receives the code's output and can use it in its response.

With structured output, you can constrain Gemini to respond with JSON. This is particularly useful for integrating the model's output into applications.

Function calling connects the thinking model to external tools and APIs, so it can reason about when to call the right function and what parameters to provide.

You can try examples of using tools with thinking models in the Thinking cookbook.
