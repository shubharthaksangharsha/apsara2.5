
Class LiveExperimental
Live class encapsulates the configuration for live interaction with the Generative Language API. It embeds ApiClient for general API settings.

Defined in live.ts:64
Constructors
C
constructor
Methods
M
connect
constructor
new Live(
    apiClient: ApiClient,
    auth: Auth,
    webSocketFactory: WebSocketFactory,
): Live
Experimental
Parameters
apiClient: ApiClient
auth: Auth
webSocketFactory: WebSocketFactory
Returns Live
Defined in live.ts:65
connect
connect(params: LiveConnectParameters): Promise<Session>
Experimental
Establishes a connection to the specified model with the given configuration and returns a Session object representing that connection.

Parameters
params: LiveConnectParameters
The parameters for establishing a connection to the model.

Returns Promise<Session>
A live session.

Remarks
Example
let model: string;
if (GOOGLE_GENAI_USE_VERTEXAI) {
  model = 'gemini-2.0-flash-live-preview-04-09';
} else {
  model = 'gemini-2.0-flash-live-001';
}
const session = await ai.live.connect({
  model: model,
  config: {
    responseModalities: [Modality.AUDIO],
  },
  callbacks: {
    onopen: () => {
      console.log('Connected to the socket.');
    },
    onmessage: (e: MessageEvent) => {
      console.log('Received message from the server: %s\n', debug(e.data));
    },
    onerror: (e: ErrorEvent) => {
      console.log('Error occurred: %s\n', debug(e.error));
    },
    onclose: (e: CloseEvent) => {
      console.log('Connection closed.');
    },
  },
});
Copy
Defined in live.ts:112
@google/genailiveSession
Class SessionExperimental
Represents a connection to the API.

Defined in live.ts:212
Constructors
C
constructor
Properties
P
conn
Methods
M
close
M
sendClientContent
M
sendRealtimeInput
M
sendToolResponse
constructor
new Session(conn: WebSocket, apiClient: ApiClient): Session
Experimental
Parameters
conn: WebSocket
apiClient: ApiClient
Returns Session
Defined in live.ts:213
Readonly
Experimental
conn
conn: WebSocket
Defined in live.ts:214
close
close(): void
Experimental
Terminates the WebSocket connection.

Returns void
Example
let model: string;
if (GOOGLE_GENAI_USE_VERTEXAI) {
  model = 'gemini-2.0-flash-live-preview-04-09';
} else {
  model = 'gemini-2.0-flash-live-001';
}
const session = await ai.live.connect({
  model: model,
  config: {
    responseModalities: [Modality.AUDIO],
  }
});

session.close();
Copy
Defined in live.ts:454
sendClientContent
sendClientContent(params: LiveSendClientContentParameters): void
Experimental
Send a message over the established connection.

Parameters
params: LiveSendClientContentParameters
Contains two optional properties, turns and turnComplete.

turns will be converted to a Content[]
turnComplete: true [default] indicates that you are done sending content and expect a response. If turnComplete: false, the server will wait for additional messages before starting generation.
Returns void
Remarks
There are two ways to send messages to the live API: sendClientContent and sendRealtimeInput.

sendClientContent messages are added to the model context in order. Having a conversation using sendClientContent messages is roughly equivalent to using the Chat.sendMessageStream, except that the state of the chat history is stored on the API server instead of locally.

Because of sendClientContent's order guarantee, the model cannot respons as quickly to sendClientContent messages as to sendRealtimeInput messages. This makes the biggest difference when sending objects that have significant preprocessing time (typically images).

The sendClientContent message sends a Content[] which has more options than the Blob sent by sendRealtimeInput.

So the main use-cases for sendClientContent over sendRealtimeInput are:

Sending anything that can't be represented as a Blob (text, sendClientContent({turns="Hello?"})).
Managing turns when not using audio input and voice activity detection. (sendClientContent({turnComplete:true}) or the short form sendClientContent())
Prefilling a conversation context
sendClientContent({
    turns: [
      Content({role:user, parts:...}),
      Content({role:user, parts:...}),
      ...
    ]
})
Copy
Defined in live.ts:362
sendRealtimeInput
sendRealtimeInput(params: LiveSendRealtimeInputParameters): void
Experimental
Send a realtime message over the established connection.

Parameters
params: LiveSendRealtimeInputParameters
Contains one property, media.

media will be converted to a Blob
Returns void
Remarks
Use sendRealtimeInput for realtime audio chunks and video frames (images).

With sendRealtimeInput the api will respond to audio automatically based on voice activity detection (VAD).

sendRealtimeInput is optimized for responsivness at the expense of deterministic ordering guarantees. Audio and video tokens are to the context when they become available.

Note: The Call signature expects a Blob object, but only a subset of audio and image mimetypes are allowed.

Defined in live.ts:397
sendToolResponse
sendToolResponse(params: LiveSendToolResponseParameters): void
Experimental
Send a function response message over the established connection.

Parameters
params: LiveSendToolResponseParameters
Contains property functionResponses.

functionResponses will be converted to a functionResponses[]
Returns void
Remarks
Use sendFunctionResponse to reply to LiveServerToolCall from the server.

Use types.LiveConnectConfig#tools to configure the callable functions.

Defined in live.ts:421

@google/genaitypesLiveClientToolResponse
Class LiveClientToolResponse
Client generated response to a ToolCall received from the server.

Individual FunctionResponse objects are matched to the respective FunctionCall objects by the id field.

Note that in the unary and server-streaming GenerateContent APIs function calling happens by exchanging the Content parts, while in the bidi GenerateContent APIs function calling happens over this dedicated set of messages.

Defined in types.ts:2684
Constructors
C
constructor
Properties
P
functionResponses?
constructor
new LiveClientToolResponse(): LiveClientToolResponse
Returns LiveClientToolResponse
Optional
functionResponses
functionResponses?: FunctionResponse[]
The response to the function calls.

Defined in types.ts:2686

@google/genaitypesLiveSendToolResponseParameters
Class LiveSendToolResponseParameters
Parameters for sending tool responses to the live API.

Defined in types.ts:2815
Constructors
C
constructor
Properties
P
functionResponses
constructor
new LiveSendToolResponseParameters(): LiveSendToolResponseParameters
Returns LiveSendToolResponseParameters
functionResponses
functionResponses: FunctionResponse | FunctionResponse[] = []
Tool responses to send to the session.

Defined in types.ts:2817

@google/genaitypesActivityEnd
Interface ActivityEnd
Marks the end of user activity.

This can only be sent if automatic (i.e. server-side) activity detection is disabled.

Defined in types.ts:2648

@google/genaitypesActivityStart
Interface ActivityStart
Marks the start of user activity.

This can only be sent if automatic (i.e. server-side) activity detection is disabled.

Defined in types.ts:2641

@google/genaitypesLiveCallbacks
Interface LiveCallbacks
Callbacks for the live API.

interface LiveCallbacks {
    onclose?: null | (e: CloseEvent) => void;
    onerror?: null | (e: ErrorEvent) => void;
    onmessage: (e: LiveServerMessage) => void;
    onopen?: null | () => void;
}
Defined in types.ts:2081
Properties
P
onclose?
P
onerror?
P
onmessage
P
onopen?
Optional
onclose
onclose?: null | (e: CloseEvent) => void
Called when the websocket connection is closed.

Defined in types.ts:2097
Optional
onerror
onerror?: null | (e: ErrorEvent) => void
Called when an error occurs.

Defined in types.ts:2093
onmessage
onmessage: (e: LiveServerMessage) => void
Called when a message is received from the server.

Defined in types.ts:2089
Optional
onopen
onopen?: null | () => void
Called when the websocket connection is established.

Defined in types.ts:2085

@google/genaitypesLiveClientContent
Interface LiveClientContent
Incremental update of the current conversation delivered from the client.

All the content here will unconditionally be appended to the conversation history and used as part of the prompt to the model to generate content.

A message here will interrupt any current model generation.

interface LiveClientContent {
    turnComplete?: boolean;
    turns?: Content[];
}
Defined in types.ts:2622
Properties
P
turnComplete?
P
turns?
Optional
turnComplete
turnComplete?: boolean
If true, indicates that the server content generation should start with the currently accumulated prompt. Otherwise, the server will await additional messages before starting generation.

Defined in types.ts:2633
Optional
turns
turns?: Content[]
The content appended to the current conversation with the model.

For single-turn queries, this is a single instance. For multi-turn queries, this is a repeated field that contains conversation history and latest request.

Defined in types.ts:2629


@google/genaitypesLiveClientMessage
Interface LiveClientMessage
Messages sent by the client in the API call.

interface LiveClientMessage {
    clientContent?: LiveClientContent;
    realtimeInput?: LiveClientRealtimeInput;
    setup?: LiveClientSetup;
    toolResponse?: LiveClientToolResponse;
}
Defined in types.ts:2690
Properties
P
clientContent?
P
realtimeInput?
P
setup?
P
toolResponse?
Optional
clientContent
clientContent?: LiveClientContent
Incremental update of the current conversation delivered from the client.

Defined in types.ts:2694
Optional
realtimeInput
realtimeInput?: LiveClientRealtimeInput
User input that is sent in real time.

Defined in types.ts:2696
Optional
setup
setup?: LiveClientSetup
Message to be sent by the system when connecting to the API. SDK users should not send this message.

Defined in types.ts:2692
Optional
toolResponse
toolResponse?: LiveClientToolResponse
Response to a ToolCallMessage received from the server.

Defined in types.ts:2698

@google/genaitypesLiveClientRealtimeInput
Interface LiveClientRealtimeInput
User input that is sent in real time.

This is different from LiveClientContent in a few ways:

Can be sent continuously without interruption to model generation.
If there is a need to mix data interleaved across the LiveClientContent and the LiveClientRealtimeInput, server attempts to optimize for best response, but there are no guarantees.
End of turn is not explicitly specified, but is rather derived from user activity (for example, end of speech).
Even before the end of turn, the data is processed incrementally to optimize for a fast start of the response from the model.
Is always assumed to be the user's input (cannot be used to populate conversation history).
interface LiveClientRealtimeInput {
    activityEnd?: ActivityEnd;
    activityStart?: ActivityStart;
    mediaChunks?: Blob[];
}
Defined in types.ts:2665
Properties
P
activityEnd?
P
activityStart?
P
mediaChunks?
Optional
activityEnd
activityEnd?: ActivityEnd
Marks the end of user activity.

Defined in types.ts:2671
Optional
activityStart
activityStart?: ActivityStart
Marks the start of user activity.

Defined in types.ts:2669
Optional
mediaChunks
mediaChunks?: Blob[]
Inlined bytes data for media input.

Defined in types.ts:2667

@google/genaitypesLiveClientSetup
Interface LiveClientSetup
Message contains configuration that will apply for the duration of the streaming session.

interface LiveClientSetup {
    contextWindowCompression?: ContextWindowCompressionConfig;
    generationConfig?: GenerationConfig;
    model?: string;
    realtimeInputConfig?: RealtimeInputConfig;
    sessionResumption?: SessionResumptionConfig;
    systemInstruction?: ContentUnion;
    tools?: ToolListUnion;
}
Defined in types.ts:2583
Properties
P
contextWindowCompression?
P
generationConfig?
P
model?
P
realtimeInputConfig?
P
sessionResumption?
P
systemInstruction?
P
tools?
Optional
contextWindowCompression
contextWindowCompression?: ContextWindowCompressionConfig
Configures context window compression mechanism.

If included, server will compress context window to fit into given length.

Defined in types.ts:2612
Optional
generationConfig
generationConfig?: GenerationConfig
The generation configuration for the session. Note: only a subset of fields are supported.

Defined in types.ts:2592
Optional
model
model?: string
The fully qualified name of the publisher model or tuned model endpoint to use.

Defined in types.ts:2588
Optional
realtimeInputConfig
realtimeInputConfig?: RealtimeInputConfig
Configures the realtime input behavior in BidiGenerateContent.

Defined in types.ts:2604
Optional
sessionResumption
sessionResumption?: SessionResumptionConfig
Configures session resumption mechanism.

If included server will send SessionResumptionUpdate messages.

Defined in types.ts:2608
Optional
systemInstruction
systemInstruction?: ContentUnion
The user provided system instructions for the model. Note: only text should be used in parts and content in each part will be in a separate paragraph.

Defined in types.ts:2596
Optional
tools
tools?: ToolListUnion
A list of Tools the model may use to generate the next response.

A Tool is a piece of code that enables the system to interact with external systems to perform an action, or set of actions, outside of knowledge and scope of the model.

Defined in types.ts:2602

@google/genaitypesLiveConnectConfig
Interface LiveConnectConfig
Session config for the API connection.

interface LiveConnectConfig {
    contextWindowCompression?: ContextWindowCompressionConfig;
    generationConfig?: GenerationConfig;
    realtimeInputConfig?: RealtimeInputConfig;
    responseModalities?: Modality[];
    sessionResumption?: SessionResumptionConfig;
    speechConfig?: SpeechConfig;
    systemInstruction?: ContentUnion;
    tools?: ToolListUnion;
}
Defined in types.ts:2702
Properties
P
contextWindowCompression?
P
generationConfig?
P
realtimeInputConfig?
P
responseModalities?
P
sessionResumption?
P
speechConfig?
P
systemInstruction?
P
tools?
Optional
contextWindowCompression
contextWindowCompression?: ContextWindowCompressionConfig
Configures context window compression mechanism.

If included, server will compress context window to fit into given length.

Defined in types.ts:2731
Optional
generationConfig
generationConfig?: GenerationConfig
The generation configuration for the session.

Defined in types.ts:2704
Optional
realtimeInputConfig
realtimeInputConfig?: RealtimeInputConfig
Configures the realtime input behavior in BidiGenerateContent.

Defined in types.ts:2727
Optional
responseModalities
responseModalities?: Modality[]
The requested modalities of the response. Represents the set of modalities that the model can return. Defaults to AUDIO if not specified.

Defined in types.ts:2708
Optional
sessionResumption
sessionResumption?: SessionResumptionConfig
Configures session resumption mechanism.

If included the server will send SessionResumptionUpdate messages.

Defined in types.ts:2725
Optional
speechConfig
speechConfig?: SpeechConfig
The speech generation configuration.

Defined in types.ts:2711
Optional
systemInstruction
systemInstruction?: ContentUnion
The user provided system instructions for the model. Note: only text should be used in parts and content in each part will be in a separate paragraph.

Defined in types.ts:2715
Optional
tools
tools?: ToolListUnion
A list of Tools the model may use to generate the next response.

A Tool is a piece of code that enables the system to interact with external systems to perform an action, or set of actions, outside of knowledge and scope of the model.

Defined in types.ts:2721

@google/genaitypesLiveConnectParameters
Interface LiveConnectParameters
Parameters for connecting to the live API.

interface LiveConnectParameters {
    callbacks: LiveCallbacks;
    config?: LiveConnectConfig;
    model: string;
}
Defined in types.ts:2735
Properties
P
callbacks
P
config?
P
model
callbacks
callbacks: LiveCallbacks
callbacks

Defined in types.ts:2740
Optional
config
config?: LiveConnectConfig
Optional configuration parameters for the request.

Defined in types.ts:2743
model
model: string
ID of the model to use. For a list of models, see Google models <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>_.

Defined in types.ts:2738

@google/genaitypesLiveSendClientContentParameters
Interface LiveSendClientContentParameters
Parameters for sending client content to the live API.

interface LiveSendClientContentParameters {
    turnComplete?: boolean;
    turns?: ContentListUnion;
}
Defined in types.ts:2795
Properties
P
turnComplete?
P
turns?
Optional
turnComplete
turnComplete?: boolean
If true, indicates that the server content generation should start with the currently accumulated prompt. Otherwise, the server will await additional messages before starting generation.

Defined in types.ts:2801
Optional
turns
turns?: ContentListUnion
Client content to send to the session.

Defined in types.ts:2797

@google/genaitypesLiveSendRealtimeInputParameters
Interface LiveSendRealtimeInputParameters
Parameters for sending realtime input to the live API.

interface LiveSendRealtimeInputParameters {
    activityEnd?: ActivityEnd;
    activityStart?: ActivityStart;
    media: Blob;
}
Defined in types.ts:2805
Properties
P
activityEnd?
P
activityStart?
P
media
Optional
activityEnd
activityEnd?: ActivityEnd
Marks the end of user activity.

Defined in types.ts:2811
Optional
activityStart
activityStart?: ActivityStart
Marks the start of user activity.

Defined in types.ts:2809
media
media: Blob
Realtime input to send to the session.

Defined in types.ts:2807

@google/genaitypesLiveServerContent
Interface LiveServerContent
Incremental server update generated by the model in response to client messages.

Content is generated as quickly as possible, and not in real time. Clients may choose to buffer and play it out in real time.

interface LiveServerContent {
    generationComplete?: boolean;
    interrupted?: boolean;
    modelTurn?: Content;
    turnComplete?: boolean;
}
Defined in types.ts:2414
Properties
P
generationComplete?
P
interrupted?
P
modelTurn?
P
turnComplete?
Optional
generationComplete
generationComplete?: boolean
If true, indicates that the model is done generating. When model is interrupted while generating there will be no generation_complete message in interrupted turn, it will go through interrupted > turn_complete. When model assumes realtime playback there will be delay between generation_complete and turn_complete that is caused by model waiting for playback to finish. If true, indicates that the model has finished generating all content. This is a signal to the client that it can stop sending messages.

Defined in types.ts:2429
Optional
interrupted
interrupted?: boolean
If true, indicates that a client message has interrupted current model generation. If the client is playing out the content in realtime, this is a good signal to stop and empty the current queue.

Defined in types.ts:2420
Optional
modelTurn
modelTurn?: Content
The content that the model has generated as part of the current conversation with the user.

Defined in types.ts:2416
Optional
turnComplete
turnComplete?: boolean
If true, indicates that the model is done generating. Generation will only start in response to additional client messages. Can be set alongside content, indicating that the content is the last in the turn.

Defined in types.ts:2418

@google/genaitypesLiveServerSessionResumptionUpdate
Interface LiveServerSessionResumptionUpdate
Update of the session resumption state.

Only sent if session_resumption was set in the connection config.

interface LiveServerSessionResumptionUpdate {
    lastConsumedClientMessageIndex?: string;
    newHandle?: string;
    resumable?: boolean;
}
Defined in types.ts:2486
Properties
P
lastConsumedClientMessageIndex?
P
newHandle?
P
resumable?
Optional
lastConsumedClientMessageIndex
lastConsumedClientMessageIndex?: string
Index of last message sent by client that is included in state represented by this SessionResumptionToken. Only sent when SessionResumptionConfig.transparent is set.

Presence of this index allows users to transparently reconnect and avoid issue of losing some part of realtime audio input/video. If client wishes to temporarily disconnect (for example as result of receiving GoAway) they can do it without losing state by buffering messages sent since last SessionResmumptionTokenUpdate. This field will enable them to limit buffering (avoid keeping all requests in RAM).

Note: This should not be used for when resuming a session at some time later -- in those cases partial audio and video frames arelikely not needed.

Defined in types.ts:2496
Optional
newHandle
newHandle?: string
New handle that represents state that can be resumed. Empty if resumable=false.

Defined in types.ts:2488
Optional
resumable
resumable?: boolean
True if session can be resumed at this point. It might be not possible to resume session at some points. In that case we send update empty new_handle and resumable=false. Example of such case could be model executing function calls or just generating. Resuming session (using previous session token) in such state will result in some data loss.

Defined in types.ts:2490

@google/genaitypesLiveServerSetupComplete
Interface LiveServerSetupComplete
Sent in response to a LiveGenerateContentSetup message from the client.

Defined in types.ts:2407

@google/genaitypesLiveServerToolCall
Interface LiveServerToolCall
Request for the client to execute the function_calls and return the responses with the matching ids.

interface LiveServerToolCall {
    functionCalls?: FunctionCall[];
}
Defined in types.ts:2433
Properties
P
functionCalls?
Optional
functionCalls
functionCalls?: FunctionCall[]
The function call to be executed.

Defined in types.ts:2435

@google/genaitypesLiveServerToolCallCancellation
Interface LiveServerToolCallCancellation
Notification for the client that a previously issued ToolCallMessage with the specified ids should have been not executed and should be cancelled.

If there were side-effects to those tool calls, clients may attempt to undo the tool calls. This message occurs only in cases where the clients interrupt server turns.

interface LiveServerToolCallCancellation {
    ids?: string[];
}
Defined in types.ts:2444
Properties
P
ids?
Optional
ids
ids?: string[]
The ids of the tool calls to be cancelled.

Defined in types.ts:2446

@google/genaitypesPart
Interface Part
A datatype containing media content.

Exactly one field within a Part should be set, representing the specific type of content being conveyed. Using multiple fields within the same Part instance is considered invalid.

interface Part {
    codeExecutionResult?: CodeExecutionResult;
    executableCode?: ExecutableCode;
    fileData?: FileData;
    functionCall?: FunctionCall;
    functionResponse?: FunctionResponse;
    inlineData?: Blob;
    text?: string;
    thought?: boolean;
    videoMetadata?: VideoMetadata;
}
Defined in types.ts:319
Properties
P
codeExecutionResult?
P
executableCode?
P
fileData?
P
functionCall?
P
functionResponse?
P
inlineData?
P
text?
P
thought?
P
videoMetadata?
Optional
codeExecutionResult
codeExecutionResult?: CodeExecutionResult
Optional. Result of executing the [ExecutableCode].

Defined in types.ts:325
Optional
executableCode
executableCode?: ExecutableCode
Optional. Code generated by the model that is meant to be executed.

Defined in types.ts:327
Optional
fileData
fileData?: FileData
Optional. URI based data.

Defined in types.ts:329
Optional
functionCall
functionCall?: FunctionCall
Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values.

Defined in types.ts:331
Optional
functionResponse
functionResponse?: FunctionResponse
Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.

Defined in types.ts:333
Optional
inlineData
inlineData?: Blob
Optional. Inlined bytes data.

Defined in types.ts:335
Optional
text
text?: string
Optional. Text part (can be code).

Defined in types.ts:337
Optional
thought
thought?: boolean
Indicates if the part is thought from the model.

Defined in types.ts:323
Optional
videoMetadata
videoMetadata?: VideoMetadata
Metadata for a given video.

Defined in types.ts:321

@google/genaitypesRealtimeInputConfig
Interface RealtimeInputConfig
Marks the end of user activity.

This can only be sent if automatic (i.e. server-side) activity detection is disabled.

interface RealtimeInputConfig {
    activityHandling?: ActivityHandling;
    automaticActivityDetection?: AutomaticActivityDetection;
    turnCoverage?: TurnCoverage;
}
Defined in types.ts:2536
Properties
P
activityHandling?
P
automaticActivityDetection?
P
turnCoverage?
Optional
activityHandling
activityHandling?: ActivityHandling
Defines what effect activity has.

Defined in types.ts:2540
Optional
automaticActivityDetection
automaticActivityDetection?: AutomaticActivityDetection
If not set, automatic activity detection is enabled by default. If automatic voice detection is disabled, the client must send activity signals.

Defined in types.ts:2538
Optional
turnCoverage
turnCoverage?: TurnCoverage
Defines which input is included in the user's turn.

Defined in types.ts:2542
