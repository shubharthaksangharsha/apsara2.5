Use the files I have attached to create a Python Backend server for my app call Apsara-2.5 I got my gemini key as environment key "gemini". 



Now use this all info to create a backend server as follows:- 

1. User can create a conversation with a session id and maintain a conversation history. the history should be saved locally in a folder call data/history

2. Each conversation should be multi-turn conversation where user can choose a specific model and in start of the model can choose which tools/system instruction it needed. 

3. user can edit their previous message and all the convo will start from that point only. 

4. User can choose diff models whatever are available

5. user can choose the tool capiblities to enable the tool or disable the tools. 

6. lastly i want a functionality where user send a query and depending on the level of query, apsara will choose the best model to do that conversation (we can implment this step for later) 

but first implement other steps 



image_gen_docs:- 

Generate imagesThe Gemini API supports image generation using Gemini 2.0 Flash Experimental and using Imagen 3. This guide helps you get started with both models.

Before you begin



Before calling the Gemini API, ensure you have your SDK of choice installed, and a Gemini API key configured and ready to use.

Generate images using Gemini



Gemini 2.0 Flash Experimental supports the ability to output text and inline images. This lets you use Gemini to conversationally edit images or generate outputs with interwoven text (for example, generating a blog post with text and images in a single turn). All generated images include a SynthID watermark, and images in Google AI Studio include a visible watermark as well.

Note: Make sure to include responseModalities: ["Text", "Image"] in your generation configuration for text and image output with gemini-2.0-flash-exp-image-generation. Image only is not allowed.

The following example shows how to use Gemini 2.0 to generate text-and-image output:

Python

JavaScript

REST



from google import genaifrom google.genai import typesfrom PIL import Imagefrom io import BytesIOimport base64client = genai.Client()contents = ('Hi, can you create a 3d rendered image of a pig '

            'with wings and a top hat flying over a happy '

            'futuristic scifi city with lots of greenery?')response = client.models.generate_content(

    model="gemini-2.0-flash-exp-image-generation",

    contents=contents,

    config=types.GenerateContentConfig(

      response_modalities=['Text', 'Image']

    ))for part in response.candidates[0].content.parts:

  if part.text is not None:

    print(part.text)

  elif part.inline_data is not None:

    image = Image.open(BytesIO((part.inline_data.data)))

    image.save('gemini-native-image.png')

    image.show()

AI-generated image of a fantastical flying pig

Depending on the prompt and context, Gemini will generate content in different modes (text to image, text to image and text, etc.). Here are some examples:

Text to imageExample prompt: "Generate an image of the Eiffel tower with fireworks in the background."

Text to image(s) and text (interleaved)Example prompt: "Generate an illustrated recipe for a paella."

Image(s) and text to image(s) and text (interleaved)Example prompt: (With an image of a furnished room) "What other color sofas would work in my space? can you update the image?"

Image editing (text and image to image)Example prompt: "Edit this image to make it look like a cartoon"

Example prompt: [image of a cat] + [image of a pillow] + "Create a cross stitch of my cat on this pillow."

Multi-turn image editing (chat)Example prompts: [upload an image of a blue car.] "Turn this car into a convertible." "Now change the color to yellow."

Image editing with Gemini



To perform image editing, add an image as input. The following example demonstrats uploading base64 encoded images. For multiple images and larger payloads, check the image input section.

Python

JavaScript

REST



from google import genaifrom google.genai import typesfrom PIL import Imagefrom io import BytesIOimport PIL.Imageimage = PIL.Image.open('/path/to/image.png')client = genai.Client()text_input = ('Hi, This is a picture of me.'

            'Can you add a llama next to me?',)response = client.models.generate_content(

    model="gemini-2.0-flash-exp-image-generation",

    contents=[text_input, image],

    config=types.GenerateContentConfig(

      response_modalities=['Text', 'Image']

    ))for part in response.candidates[0].content.parts:

  if part.text is not None:

    print(part.text)

  elif part.inline_data is not None:

    image = Image.open(BytesIO(part.inline_data.data))

    image.show()

Limitations

For best performance, use the following languages: EN, es-MX, ja-JP, zh-CN, hi-IN.

Image generation does not support audio or video inputs.

Image generation may not always trigger:The model may output text only. Try asking for image outputs explicitly (e.g. "generate an image", "provide images as you go along", "update the image").

The model may stop generating partway through. Try again or try a different prompt.

When generating text for an image, Gemini works best if you first generate the text and then ask for an image with the text.







all models:- 

Gemini models

2.5 Pro 



Our most powerful thinking model with maximum response accuracy and state-of-the-art performance



Input audio, images, video, and text, get text responses

Tackle difficult problems, analyze large databases, and more

Best for complex coding, reasoning, and multimodal understanding

2.0 Flash 



Our newest multimodal model, with next generation features and improved capabilities



Input audio, images, video, and text, get text responses

Generate code and images, extract data, analyze files, generate graphs, and more

Low latency, enhanced performance, built to power agentic experiences

2.0 Flash-Lite



A Gemini 2.0 Flash model optimized for cost efficiency and low latency



Input audio, images, video, and text, get text responses

Outperforms 1.5 Flash on the majority of benchmarks

A 1 million token context window and multimodal input, like Flash 2.0

Model variants

The Gemini API offers different models that are optimized for specific use cases. Here's a brief overview of Gemini variants that are available:



Model variant	Input(s)	Output	Optimized for

Gemini 2.5 Pro Preview

gemini-2.5-pro-preview-03-25	Audio, images, videos, and text	Text	Enhanced thinking and reasoning, multimodal understanding, advanced coding, and more

Gemini 2.0 Flash

gemini-2.0-flash	Audio, images, videos, and text	Text, images (experimental), and audio (coming soon)	Next generation features, speed, thinking, realtime streaming, and multimodal generation

Gemini 2.0 Flash-Lite

gemini-2.0-flash-lite	Audio, images, videos, and text	Text	Cost efficiency and low latency

Gemini 1.5 Flash

gemini-1.5-flash	Audio, images, videos, and text	Text	Fast and versatile performance across a diverse variety of tasks

Gemini 1.5 Flash-8B

gemini-1.5-flash-8b	Audio, images, videos, and text	Text	High volume and lower intelligence tasks

Gemini 1.5 Pro

gemini-1.5-pro	Audio, images, videos, and text	Text	Complex reasoning tasks requiring more intelligence

Gemini Embedding

gemini-embedding-exp	Text	Text embeddings	Measuring the relatedness of text strings

Imagen 3

imagen-3.0-generate-002	Text	Images	Our most advanced image generation model

Veo 2

veo-2.0-generate-001	Text, images	Video	High quality video generation

Gemini 2.0 Flash Live

gemini-2.0-flash-live-001	Audio, video, and text	Text, audio	Low-latency bidirectional voice and video interactions

You can view the rate limits for each model on the rate limits page.



Gemini 2.5 Pro Preview

Gemini 2.5 Pro is our state-of-the-art thinking model, capable of reasoning over complex problems in code, math, and STEM, as well as analyzing large datasets, codebases, and documents using long context.



Try in Google AI Studio



Model details

Property	Description

Model code	Paid: gemini-2.5-pro-preview-03-25, Experimental: gemini-2.5-pro-exp-03-25

Supported data types

Inputs



Audio, images, video, and text



Output



Text



Token limits[*]

Input token limit



1,048,576



Output token limit



65,536



Capabilities

Structured outputs



Supported



Caching



Not supported



Tuning



Not supported



Function calling



Supported



Code execution



Supported



Search grounding



Supported



Image generation



Not supported



Native tool use



Supported



Audio generation



Not supported



Live API



Not supported



Thinking



Supported



Versions	

Read the model version patterns for more details.

Preview: gemini-2.5-pro-preview-03-25

Experimental: gemini-2.5-pro-exp-03-25

Latest update	March 2025

Knowledge cutoff	January 2025

Gemini 2.0 Flash

Gemini 2.0 Flash delivers next-gen features and improved capabilities, including superior speed, native tool use, multimodal generation, and a 1M token context window.



Try in Google AI Studio



Model details

Property	Description

Model code	models/gemini-2.0-flash

Supported data types

Inputs



Audio, images, video, and text



Output



Text, images (experimental), and audio(coming soon)



Token limits[*]

Input token limit



1,048,576



Output token limit



8,192



Capabilities

Structured outputs



Supported



Caching



Coming soon



Tuning



Not supported



Function calling



Supported



Code execution



Supported



Search



Supported



Image generation



Experimental



Native tool use



Supported



Audio generation



Coming soon



Live API



Experimental



Thinking



Experimental



Versions	

Read the model version patterns for more details.

Latest: gemini-2.0-flash

Stable: gemini-2.0-flash-001

Experimental: gemini-2.0-flash-exp and gemini-2.0-flash-exp-image-generation point to the same underlying model

Experimental: gemini-2.0-flash-thinking-exp-01-21

Latest update	February 2025

Knowledge cutoff	August 2024

Gemini 2.0 Flash-Lite

A Gemini 2.0 Flash model optimized for cost efficiency and low latency.



Try in Google AI Studio



Model details

Property	Description

Model code	models/gemini-2.0-flash-lite

Supported data types

Inputs



Audio, images, video, and text



Output



Text



Token limits[*]

Input token limit



1,048,576



Output token limit



8,192



Capabilities

Structured outputs



Supported



Caching



Not supported



Tuning



Not supported



Function calling



Not supported



Code execution



Not supported



Search



Not supported



Image generation



Not supported



Native tool use



Not supported



Audio generation



Not supported



Live API



Not supported



Versions	

Read the model version patterns for more details.

Latest: gemini-2.0-flash-lite

Stable: gemini-2.0-flash-lite-001

Latest update	February 2025

Knowledge cutoff	August 2024

Gemini 1.5 Flash

Gemini 1.5 Flash is a fast and versatile multimodal model for scaling across diverse tasks.



Try in Google AI Studio



Model details

Property	Description

Model code	models/gemini-1.5-flash

Supported data types

Inputs



Audio, images, video, and text



Output



Text



Token limits[*]

Input token limit



1,048,576



Output token limit



8,192



Audio/visual specs

Maximum number of images per prompt



3,600



Maximum video length



1 hour



Maximum audio length



Approximately 9.5 hours



Capabilities

System instructions



Supported



JSON mode



Supported



JSON schema



Supported



Adjustable safety settings



Supported



Caching



Supported



Tuning



Supported



Function calling



Supported



Code execution



Supported



Live API



Not supported



Versions	

Read the model version patterns for more details.

Latest: gemini-1.5-flash-latest

Latest stable: gemini-1.5-flash

Stable:

gemini-1.5-flash-001

gemini-1.5-flash-002

Latest update	September 2024

Gemini 1.5 Flash-8B

Gemini 1.5 Flash-8B is a small model designed for lower intelligence tasks.



Try in Google AI Studio



Model details

Property	Description

Model code	models/gemini-1.5-flash-8b

Supported data types

Inputs



Audio, images, video, and text



Output



Text



Token limits[*]

Input token limit



1,048,576



Output token limit



8,192



Audio/visual specs

Maximum number of images per prompt



3,600



Maximum video length



1 hour



Maximum audio length



Approximately 9.5 hours



Capabilities

System instructions



Supported



JSON mode



Supported



JSON schema



Supported



Adjustable safety settings



Supported



Caching



Supported



Tuning



Supported



Function calling



Supported



Code execution



Supported



Live API



Not supported



Versions	

Read the model version patterns for more details.

Latest: gemini-1.5-flash-8b-latest

Latest stable: gemini-1.5-flash-8b

Stable:

gemini-1.5-flash-8b-001

Latest update	October 2024

Gemini 1.5 Pro

Try Gemini 2.0 Pro Experimental, our most advanced Gemini model to date.



Gemini 1.5 Pro is a mid-size multimodal model that is optimized for a wide-range of reasoning tasks. 1.5 Pro can process large amounts of data at once, including 2 hours of video, 19 hours of audio, codebases with 60,000 lines of code, or 2,000 pages of text.



Try in Google AI Studio



Model details

Property	Description

Model code	models/gemini-1.5-pro

Supported data types

Inputs



Audio, images, video, and text



Output



Text



Token limits[*]

Input token limit



2,097,152



Output token limit



8,192



Audio/visual specs

Maximum number of images per prompt



7,200



Maximum video length



2 hours



Maximum audio length



Approximately 19 hours



Capabilities

System instructions



Supported



JSON mode



Supported



JSON schema



Supported



Adjustable safety settings



Supported



Caching



Supported



Tuning



Not supported



Function calling



Supported



Code execution



Supported



Live API



Not supported



Versions	

Read the model version patterns for more details.

Latest: gemini-1.5-pro-latest

Latest stable: gemini-1.5-pro

Stable:

gemini-1.5-pro-001

gemini-1.5-pro-002

Latest update	September 2024



Gemini 2.0 Flash Live

The Gemini 2.0 Flash Live model works with the Live API to enable low-latency bidirectional voice and video interactions with Gemini. The model can process text, audio, and video input, and it can provide text and audio output.



Try in Google AI Studio



Model details

Property	Description

Model code	models/gemini-2.0-flash-live-001

Supported data types

Inputs



Audio, video, and text



Output



Text, and audio



Token limits[*]

Input token limit



1,048,576



Output token limit



8,192



Capabilities

Structured outputs



Supported



Caching



Not supported



Tuning



Not supported



Function calling



Supported



Code execution



Supported



Search



Supported



Image generation



Not supported



Native tool use



Supported



Audio generation



Supported



Thinking



Not supported



Versions	

Read the model version patterns for more details.

Preview: gemini-2.0-flash-live-001

Latest update	April 2025

Knowledge cutoff	August 2024




